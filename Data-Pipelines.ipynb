{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # `scikit-learn` Pipelines\n",
    " \n",
    "_Author: Carleton Smith_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "# Learning Objectives\n",
    "- Review EDA and preprocessing in pandas\n",
    "- Build a preprocessing pipeline in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Lesson Guide\n",
    "- [Acquire Data](#acquire)\n",
    "- [Sklearn Pipelines](#pipelines)\n",
    "- [Exploratory Data Analysis](#explore)\n",
    "- [Preprocessing Pipeline](#preprocess)\n",
    "- [Model Building](#modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"acquire\"></a>\n",
    "# Acquire Data\n",
    "\n",
    "For this lessons, we will use the \"Census Income\" dataset, provided by the UCI Machine Learning Repository.\n",
    "\n",
    "**Link**: https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "Our goal will be to predict if an individual's income exceeds \\$50k per year based on census data.\n",
    "\n",
    "\n",
    "**FEATURES**\n",
    "\n",
    "1. `age`: continuous.\n",
    "2. `workclass`: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "3. `fnlwgt`: continuous.\n",
    "4. `education`: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "5. `education-num`: continuous.\n",
    "6. `marital-status`: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "7. `occupation`: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "8. `race`: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "9. `sex`: Female, Male.\n",
    "10. `capital-gain`: continuous.\n",
    "11. `capital-loss`: continuous.\n",
    "12. `hours-per-week`: continuous.\n",
    "13. `native-country`: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./datasets/adult.data.txt', na_values= ' ?', header=None)\n",
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education_num',\n",
    "    'marital_status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital_gain',\n",
    "    'capital_loss',\n",
    "    'hours_per_week',\n",
    "    'native_country',\n",
    "    'income',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Add column headers using the `features` list defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the modifications we'll make at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipelines\"></a>\n",
    "# Review: Sklearn Pipelines\n",
    "---\n",
    "\n",
    "Sklearn provides a [module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline) for creating preprocessing pipelines. Some of you may be familiar. We will demonstrate Pipelines through an \"end to end\" project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult[['age']].copy()\n",
    "y = adult['fnlwgt']\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**    \n",
    "The sklearn pipeline takes a list of tuples. Each tuples is a step. The first element in a tuple is the name of the step and the second element is the class object that performs the step. Each step must have a `.fit` and a `.transform` method. The only exception to this is the last step, which can be a model class object (sklearn models do not have a `.transform` method).\n",
    "\n",
    "The output of one step becomes the input of the next step, so order matters when constructing the pipeline.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a pipeline with 2 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the pipeline with data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore\"></a>\n",
    "# Exploratory Data Analysis\n",
    "---\n",
    "\n",
    "Let's run through some basic EDA procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Show how many missing values exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: What are the data types for each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: what is the distribution of `income`? This is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Create a plot of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: What are the distributions of the numeric data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocess\"></a>\n",
    "# Preprocessing Pipeline\n",
    "---\n",
    "\n",
    "We will build this pipeline out sequentially.\n",
    "\n",
    "**PREPROCESSING STEPS**\n",
    "1. Separate target variable from features - sklearn requires this.\n",
    "2. Peform a train-test split\n",
    "3. With training data:\n",
    "    - **SEPARATE** numeric columns from categorical ones\n",
    "    - **NUMERIC DF** preprocessing:\n",
    "        - Replace nan values\n",
    "        - Standardize features\n",
    "   \n",
    "    - **CATEGORICAL DF** preprocessing:\n",
    "        - Replace nan values\n",
    "        - Create dummy variables\n",
    "    - **CONCATENATE** numeric and categorical DF\n",
    "    - **ENCODE** target variable\n",
    "<br>\n",
    "<br>\n",
    "4. Package these steps into a `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Using a list comprehension, create a list of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Using a list comprehension, create a list of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Separate target variable from features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult.drop('income', axis=1)\n",
    "y = adult['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Make a function that will extract out `X`. Call the function `feature_extractor`.\n",
    "\n",
    "- The function should accept a DataFrame and return a DataFrame with the target variable removed.\n",
    "- It's okay to hardcode the name of the target variable `income`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Peform a train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=24\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. We will make functions for the following:**\n",
    "    - **SEPARATE** numeric columns from categorical ones\n",
    "    - **NUMERIC DF** preprocessing:\n",
    "        - Replace nan values\n",
    "        - Standardize features\n",
    "   \n",
    "    - **CATEGORICAL DF** preprocessing:\n",
    "        - Replace nan values\n",
    "        - Create dummy variables\n",
    "    - **CONCATENATE** numeric and categorical DF\n",
    "    - **ENCODE** target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Create a function that will extract the categorical columns. Name this function `categorical_extractor`.\n",
    "\n",
    "- The function should accept a DataFrame and return a DataFrame with only categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Create a function that will extract the numeric columns. Name this function `numeric_extractor`.\n",
    "\n",
    "- The function should accept a DataFrame and return a DataFrame with only categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is provided for convenience. It will add column names to dummy variable columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_col_adder(array):\n",
    "    dummy_cols = []\n",
    "    for col, cat_set in zip(cat_cols, cat_pipe.named_steps['OneHotEncoder'].categories_):\n",
    "        for cat in cat_set:\n",
    "            dummy_cols.append(col+'_'+cat)\n",
    "    return pd.DataFrame(array, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FunctionTransformer`\n",
    "\n",
    "Sklearn pipelines require every step to be a `class` object with a `.fit` and `.transform` method. In order to use the functions we defined above, we will need to convert them to a \"transformer\" class object. The `FunctionTransformer` is class is designed for doing exactly that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEMO**: Use `numeric_extractor` to grab numeric columns. Then try doing the same task after converting it to a transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use numeric_extractor function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numeric_extractor to transformer, then use to transform data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Using the `num_transformer` defined above, build a pipeline for the numeric data. Call the pipeline `num_pipe`. The steps should include:\n",
    "\n",
    "1. `num_transformer`\n",
    "2. `SimpleImputer` (from sklearn.impute - use the `median` strategy)\n",
    "3. `StandardScaler` (from sklearn.preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make numeric pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll now build the pipeline for categorical data\n",
    "\n",
    "1. Use `FunctionTransformer` to transform `categorical_extractor`\n",
    "2. Use `FunctionTransformer` to transform `dummy_col_adder`\n",
    "3. Build the categorical pipeline\n",
    "\n",
    "For number 3, include the following steps:\n",
    "\n",
    "- `cat_transformer`\n",
    "- `SimpleImputer(strategy='most_frequent')`\n",
    "- `OneHotEncoder(sparse=False, handle_unknown='ignore')`\n",
    "- `dummy_col_transformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our two functions\n",
    "cat_transformer = FunctionTransformer(categorical_extractor, validate=False)\n",
    "dummy_col_transformer = FunctionTransformer(dummy_col_adder, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    ('cat_transformer', cat_transformer),\n",
    "    ('cat_im', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHotEncoder', OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "    ('dummy_col_transformer', dummy_col_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe.transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FeatureUnion`\n",
    "\n",
    "We now have two pipelines: `num_pipe` and `cat_pipe`. They each do their job and we can have them work in parallel. For this, we use the `FeatureUnion` class from the `pipeline` module. This will run each pipeline seperately and combine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make FeatureUnion\n",
    "feat_union = FeatureUnion([\n",
    "    ('num_pipe', num_pipe),\n",
    "    ('cat_pipe', cat_pipe)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_union.fit(X_train).transform(X_train)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the first 6 items are from the numeric data. The remaining columns are dummy variables from the categorical columns.\n",
    "\n",
    "\n",
    "Finally, we combine this into one pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipe = Pipeline([\n",
    "    ('feat_union', feat_union)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use this pipeline to _fit_ and _transform_ `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform training data\n",
    "X_train_prepared = pd.DataFrame(\n",
    "    feature_pipe.fit(X_train).transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns = num_cols + [col+ '_' + level.strip()\n",
    "                          for col, cat in zip(cat_cols, cat_pipe.named_steps['OneHotEncoder'].categories_)\n",
    "                          for level in cat])\n",
    "X_train_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Use this fitted pipeline to transform `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform testing data\n",
    "X_test_prepared = pd.DataFrame()\n",
    "\n",
    "# print out \n",
    "X_test_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENCODE TARGET VARIABLE**\n",
    "\n",
    "The final step is to encode the target variable `income` to be numeric. For this, we'll use `LabelEncoder` from sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: Use `LabelEncoder` to transform `y_train` so that \"<50k\" is 0 and \">=50k\" is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform y_train\n",
    "le = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform ONLY: y_test\n",
    "y_test_encoded = pd.Series(le.transform(y_test), index=y_test.index)\n",
    "y_test_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modeling\"></a>\n",
    "# Model Building\n",
    "---\n",
    "\n",
    "Now that our data is ready, we can move on to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge**: What is the first step of the modeling process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Calculate the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded.value_counts()[0] / y_test_encoded.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple model possible is using the majority class (under \\$50k) as the prediction for every value.\n",
    "\n",
    "We would achieve 76\\% accuracy if we did this. All future models must beat this baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
